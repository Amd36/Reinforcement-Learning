{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da15683",
   "metadata": {},
   "source": [
    "# Proximal Policy Optimization\n",
    "\n",
    "Here we have actors and critics and I tried to create a Ping-Pong Agent with this model. To visulize the training metrics, I used `wandb` and used the PPO model from `stable_baseline3`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f93461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import gymnasium as gym\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, VecVideoRecorder\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "import ale_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d4853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.register_envs(ale_py)\n",
    "\n",
    "config = {\n",
    "    \"env_name\": \"PongNoFrameskip-v4\",\n",
    "    \"num_envs\": 8,\n",
    "    \"total_timesteps\": int(10e6),\n",
    "    \"seed\": 42,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2438b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    project=\"PPO_Pong\",\n",
    "    config = config,\n",
    "    sync_tensorboard = True,\n",
    "    monitor_gym = True,\n",
    "    save_code = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b68894",
   "metadata": {},
   "source": [
    "This part is important where I tried to stack 4 frames and passed it as input to the model. This allows for the Agent to analyze the motion of the opponent and also the ball to prepare a counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2916dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Environment & Loading Frame Stacking\n",
    "env = make_atari_env(config[\"env_name\"], n_envs=config[\"num_envs\"], seed=config[\"seed\"]) #PongNoFrameskip-v4\n",
    "\n",
    "print(\"Environment Action Space: \", env.action_space.n)\n",
    "\n",
    "# Frame-stacking with 4 frames\n",
    "env = VecFrameStack(env, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa28df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(policy = \"CnnPolicy\",\n",
    "            env = env,\n",
    "            batch_size = 256,\n",
    "            clip_range = 0.1,\n",
    "            ent_coef = 0.01,\n",
    "            gae_lambda = 0.9,\n",
    "            gamma = 0.99,\n",
    "            learning_rate = 2.5e-4,\n",
    "            max_grad_norm = 0.5,\n",
    "            n_epochs = 4,\n",
    "            n_steps = 128,\n",
    "            vf_coef = 0.5,\n",
    "            tensorboard_log = f\"runs\",\n",
    "            verbose=1,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848111bd",
   "metadata": {},
   "source": [
    "## The Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6854ea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video Recorder for WandB integration/validation recording\n",
    "env = VecVideoRecorder(env, \"videos\", record_video_trigger=lambda x: x % 100000 == 0, video_length=2000)\n",
    "\n",
    "# Main Training Script - I reccomend (and personally did) run this on a GPU. The free t4 GPU on Colab is a great option!\n",
    "model.learn(\n",
    "    total_timesteps = config[\"total_timesteps\"],\n",
    "    callback = [\n",
    "        WandbCallback(\n",
    "        gradient_save_freq = 1000,\n",
    "        model_save_path = f\"models/{run.id}\",\n",
    "        ), \n",
    "        CheckpointCallback(save_freq=10000, save_path='./pong',\n",
    "                                         name_prefix=config[\"env_name\"]),\n",
    "        ]\n",
    ")\n",
    "\n",
    "model.save(\"ppo-PongNoFrameskip-v4.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efddd18",
   "metadata": {},
   "source": [
    "## View Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52792ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model = PPO.load(\"pong\\PongNoFrameskip-v4_5680000_steps.zip\")\n",
    "\n",
    "# Create and wrap the environment\n",
    "env = make_atari_env(\"PongNoFrameskip-v4\", n_envs=1, seed=53)\n",
    "env = VecFrameStack(env, n_stack=4)\n",
    "\n",
    "# Run the model\n",
    "obs = env.reset()\n",
    "for _ in range(5000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render(\"human\")\n",
    "\n",
    "    if dones:\n",
    "        obs = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a924b9",
   "metadata": {},
   "source": [
    "## Save as Video\n",
    "This cell saves the model performance in a `videos` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4503d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Ensure the videos directory exists\n",
    "os.makedirs(\"videos\", exist_ok=True)\n",
    "\n",
    "# Load the trained model\n",
    "model = PPO.load(\"pong/PongNoFrameskip-v4_5680000_steps.zip\")\n",
    "\n",
    "# Create and wrap the environment\n",
    "env = make_atari_env(\"PongNoFrameskip-v4\", n_envs=1, seed=153)\n",
    "env = VecFrameStack(env, n_stack=4)\n",
    "\n",
    "# Wrap with video recorder\n",
    "env = VecVideoRecorder(\n",
    "    env,\n",
    "    video_folder=\"videos\",                    # save videos here\n",
    "    record_video_trigger=lambda step: step == 0,  # record first rollout\n",
    "    video_length=3000,                        # number of steps to record\n",
    "    name_prefix=\"ppo_pong_eval\"               # filename prefix\n",
    ")\n",
    "\n",
    "# Run the model\n",
    "obs = env.reset()\n",
    "for _ in range(3000):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, rewards, dones, infos = env.step(action)\n",
    "\n",
    "    # 'dones' is an array since this is a VecEnv\n",
    "    if np.any(dones):\n",
    "        obs = env.reset()\n",
    "\n",
    "# Important: this finalizes and writes the MP4\n",
    "env.close()\n",
    "\n",
    "print(\"Video saved in ./videos/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
